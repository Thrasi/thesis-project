\documentclass[a4paper,10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[icelandic]{babel}
\usepackage[T1]{fontenc}
\usepackage{t1enc}

%opening
\title{Master Thesis Specification \\ Multi-task Human Image Parsing Using Convolutional Networks}
\author{Student: Magnús Þór Benediktsson, bened@kth.se \\ Supervisor: Hossein Azizpour \\ Examiner Danica Kragic}

\begin{document}

\maketitle

%\begin{abstract}

%\end{abstract}

\section{Background and Objective}

Deep Convolutional Networks (ConvNet) have in recent years enjoyed a remarkable success at various vision related tasks such as image classification \cite{He2015,Szegedy2014,Krizhevsky2012}, object detection \cite{Ren2015} and semantic segmentation \cite{Long2014,Noh2015}.  Conventionally, object detection and localization are approached with Region based Convolutional Networks (R-CNN) \cite{Girshick2014} that use a separate algorithm such as Selective Search \cite{Uijlings2013} to generate region proposal within an image upon which the detection ConvNet is applied.  More recently \cite{Ren2015} introduced Region Proposal Network (RPN) that shares a Fully Convolutional Network (FCN) \cite{Long2014} with a detection network that is able to simultaneously generate region proposals and extract features for classification of those regions.  This method eliminates the need for a separate region proposal algorithm that had become a bottleneck of developing state-of-the-art object detectors \cite{Ren2015}.  

In addition to increasing performance, the RPN efficiently models the two tasks of object proposal and detection with a single network.  It is efficient in the sense that the computation of convolutional features is shared between the tasks of region proposal and task of classifying what is within the proposed region.  This suggests the possibility constructing multi-task networks for efficiently solving even more tasks that share computations.  Human detection is central to many computer vision tasks such as surveillance or assisted driving. It is reasonable to expect different human related vision tasks such as human semantic segmentation \cite{Long2014,Noh2015} and pose estimation \cite{Tompson2015,Wei2016} to share many cues and features that can be efficiently combined in a single multi-task network solving more than one task simultaneously.  Just as the object detection and region proposals from \cite{Ren2015}.

%Furthermore, the RPN efficiently models the two tasks of object proposal and detection with a single network.
The main goal of this thesis is to explore the possibility of training a Deep Neural Network (DNN) that efficiently solves multiple human related tasks.  Training a single network for multiple tasks will afford the network to be trained on more data which may help regularize the network and it can be interesting to compare the performance of a multi-task network to a single-task one or see if it enables the training of larger models.  We will begin by focusing on the tasks of human semantic segmentation and pose estimation and then possibly extend towards human detection and human action recognition.

\subsection{Multi-Task Learning}
\label{sec:background:multi}
The RPN of \cite{Ren2015} is essentially an implicit multi-task network.  It solves the preliminary task of region proposal which results are then used to solve the main task of object detection.  Their network consists of shared convolutional layers, an RPN for region proposals and a Fast R-CNN \cite{Girshick2015} for detection.  The R-CNN is applied on the convolutional features corresponding to the proposals from the RPN.  By sharing the computations of the convolutional layers they achieved near real-time execution time of 5 fps \cite{Ren2015}.  

In this framework the region proposal task is a stepping stone towards main object detection.  However, we can imagine similar networks solving separate main objectives.  A network that shares convolutions only to later branch off into two or more networks that each solve their specific task such as pose estimation, segmentation etc.  In an extreme case all layers might be shared until the final output layers.  This could result in a very computationally efficient network.


\subsection{Pose Estimation}
\label{sec:background:pose}
Before the popularization of ConvNets the state-of-the-art approaches to pose estimations built on pictorial structure models \cite{Felzenszwalb2005,Yang2011}.  These methods usually express spatial correlation of body parts in tree-based graphical models that couple limbs using kinematic priors and are quite successful when all body parts appear in the image but suffer from characteristic errors stemming from correlations not modeled by the tree structure.  \cite{Ramakrishna2014} instead applied a sequential prediction framework called Pose Machines that learns an implicit spatial model from the data.  The Pose Machine consists of a series of predictors that refine the predictions of previous predictors.

Building upon \cite{Ramakrishna2014}, \cite{Wei2016} combined ConvNets and the idea of a Pose Machines into a so called Convolutional Pose Machine (CPM) with excellent results.  The CPM replaces the predictors of the Pose Machine with an FCN applied to multiple scales of the input.  The heat map outputs of these FCN's are concatenated and fed to the next stage of predictors along with the input image to refine the predictors and so on.  Furthermore, the framework allowed the problem of vanishing gradients \cite{Bengio1994} to be addressed through the use of intermediate loss functions between stages.

\subsection{Semantic Segmentation}
\label{sec:background:segmentation}
The task of semantic segmentation is to assign a semantic label to each pixel of an image.  Standard approaches prior to the success of CNNs generally applied some graphical models such as CRF with super-pixels \cite{Ladick??2009}.  The super-pixels can be assigned a label with a majority vote from pixel based assignments and the CRF is applied on top to ensure consistency and gain context from surrounding super-pixels.  

Some work has incorporated both graphical models and ConvNets such as \cite{Farabet2013}. They use a ConvNet to extract features per pixel which can be classified independently.  These pixel predictions are aggregated in a majority vote per super-pixel on top of which a CRF can be applied as mentioned above.  Furthermore, they introduced graph based method to produce a scale-invariant pre-segmentation into super-pixels and defined graphical model to refine the classification of segments.

All of these methods require detailed engineering for pre or post processing of pixel predictions in contrast to more recent purely ConvNet based approaches like \cite{Long2014,Noh2015}.  \cite{Long2014} introduced FCN's that can be applied to any size input and produces a coarse heat map for the probability that the coarse pixel belongs to a segment.  This coarse heat map was upscaled using a bilinear interpolation to produce a dense prediction.  There best performing model used 3 levels of granularity, i.e. coarse heat maps produced by the network at different stages and combined them into a final heat map.  The upscaling from earlier layers was learned by the network.  This leads to the idea of a deconvolutional network from \cite{Noh2015}.  The deconvolutional network has the same structure as \cite{Long2014}'s FCN but instead of upscaling one or more heat maps it adds a mirror image of itself and learns the parameters of deconvolutions to produce a final heat map representing the segmentation mask of an object.  


%The sharing of features among various tasks may help regularize the network and dampen overfitting.  This may enable us to learn larger networks.  More tasks that could be incorporated include Human detection, Human Action Recognition etc. There is also an computational efficiency benefit from performing two tasks with a single network as many computations will be shared across tasks.

%Stat-of-the-art ConvNet pose estimators incorporate multiple network in connected in a cascade like manner  to refine the joint locations \cite{Tompson2015,Wei2016}.  We intend to construct a single network with a recursive structure to refine model predictions.



\section{Research Question \& Method}

Section \ref{sec:arc:multi} and its subsections will be the first priority of the thesis.  Depending on the time available we will focus on the later questions which are in order of priority.


\subsection{Multi-Task Architecture}
\label{sec:arc:multi}
We will investigate architectures for a single baseline network that can be trained to solve two tasks separately.  We will use the architectures of \cite{Long2014,Noh2015} for segmentation and \cite{Tompson2015,Wei2016} for pose estimation as starting points to design our architecture.

Next step is to train the architecture on both tasks simultaneously and compare its performance to the individually trained networks.  Initially we will consider an architecture that shares convolutions and branches out into separate tasks rather than sharing weights until the last layer.



\subsubsection{Optimization of the Architecture}
\label{sec:arc:optimization}
Recent developments of novel architectures have proven beneficial to various aspects of ConvNets.  Most notably \cite{He2015,Srivastava2015} have developed methods for optimizing extremely deep networks.  Batch Normalization \cite{Ioffe2015} has been successfully applied to ConvNets to alleviate the problem of covariate shift in input data, it suggests that networks trained with Batch Normalization do not need to apply dropout \cite{Srivastava2014} which has been an important regularization mechanism for DNN's in recent years.  This is further supported by \cite{He2015}.  \cite{Szegedy2014,Szegedy2015} introduced a variety of so called inception modules that utilize $1\times 1$-convolutions and factorizes $n\times n$-convolutions into a $1\times n$-convolution and a $n\times 1$-convolution with a non-linear activation function in between.  These modules attempt to optimize model size with respect to the number of parameters.

Various architectures have been developed in order to capture multi-scale features.  \cite{Tompson2015} apply a 3 level gaussian pyramid and upscale the output of the smaller input levels.  The outputs are concatenated and fed to further convolutions.  Wei et al. \cite{Wei2016} constructed a two level multi-stage network that applies two FCN's with different receptive field sizes that produce different resolution heat maps for a set of joints.  The larger receptive field is achieved through an extra pooling layer, otherwise the networks are the same. The heat maps were rescaled and fed to the next stage of two level networks.   They demonstrated that the two level receptive field was superior to a single level.  These two methods are different in the sense that \cite{Tompson2015} rescale the input while \cite{Wei2016} use pooling to increase the receptive field.


%Wei et al. \cite{Wei2016} constructed a two level multi-stage network in order to capture both local and global cues about human poses.  They apply two FCN's with different receptive field sizes that produce different resolution heatmaps for a set of joints.  The heatmaps are rescaled and fed to the next stage of two level networks.  Their comparison demonstrated the superiority of applying the two level network over a single level network.  The second level FCN in the first stage has a larger receptive, achieved through an extra pooling layer.

These and possibly more will be considered for improving performance of our baseline architecture.  Initially we will only consider single scale networks.

Furthermore, it is of interest to examine the importance of architectural properties on our final performance.  We can run ablated studies on properties such as multi-scaling, number of layers, width of layers, batch normalization, dropout and even the point at which the network separates into different tasks to see the effect they have on the performance on our network.

\subsubsection{Recursive Architecture}
\label{sec:arc:recursive}
Stat-of-the-art ConvNet pose estimators often incorporate multiple networks connected in a cascade like manner to refine the joint locations \cite{Tompson2015,Wei2016}.  We intend to investigate the possibility of achieving similar behavior on a network with a recursive structure to refine model predictions.  This is similar in structure to a Recurrent Neural Network (RNN) \cite{Sak2014} that are often applied to sequential data.  In the context of human semantic segmentation, the network could include an extra input channel.  The network produces a heat map representing the probability of a pixel belonging to a human.  This heat map can be fed into the extra input channel along with the original image for the purpose of refining the predictions.  This can be implemented in a similar manner for multiple heat maps during pose estimation.  

The recursive structure of the network can be visualized as a cascade like in \cite{Tompson2015,Wei2016} but with shared weights between the cascade stages.  This can first be considered for the single-task trained network and later the multi-task network.


\subsection{Regularization}
\label{sec:reg}
\subsubsection{Data Augmentation}
\label{sec:reg:augmentation}
Training sets are commonly enlarged with label-preserving transformations as suggested by \cite{Krizhevsky2012} in order to reduce overfitting. Such transformations include adding random jitter to images, horizontal reflections and image cropping.  Furthermore, we will consider more task specific data augmentation such as warping poses and segmentation masks.  This can include the cropping of image pixels belonging to a segmentation mask from one image and pasting it into another image.

\subsubsection{Combined Training Sets}
\label{sec:reg:combined}
As a bi-product of multi-tasking training is that the model has access to more training data which may help battle overfitting.  We want to know if performance of each individual task can be enhanced by training a multi-task network.  

\subsection{Feature Sharing}
In addition to increased regularization from training on multiple tasks sharing convolutional features may include other benefits to performance.  Features learned by the network may be latent in other tasks and give cues that will improve performance of others. E.g. human pose estimation can help to increase true positives of semantic segmentation by providing higher level of information about body parts.  Or semantic segmentation can help decrease false positives for landmark estimation by learning general body shapes.  This is particularly easy to visualize with a recursive architecture where the prediction refinement of one task is not only refined from its own preliminary prediction but other tasks as well.  In an extreme case the final outputs of a branched architecture could be concatenated prior to a final prediction.

\section{Evaluation \& News Value}
The dataset for the human pose estimation task will be the MPII\cite{Andriluka} and for the semantic segmentation we will use Microsoft COCO\cite{Lin2014}.  We will compare the performance of the network to the baseline networks trained individually on their respective test sets.  

The capacity of a network to efficiently model multiple human related tasks is a new value onto itself as it can speedup systems that seek to solve both as demonstrated by \cite{Ren2015}.  Furthermore, the realization of some of the speculated performance enhancements discussed above would be extremely valuable.

\section{Pilot Study}
The literature study will focus on semantic segmentation and pose estimation using ConvNets as well as object detection and a general survey of the recent advances of neural networks.  All cited papers in this document will be included.  Specifically the student will familiarize himself with various deep network architectures by reading up on the  most recent developments.  This is important in order to facilitate the design of the baseline architecture and further optimizations.

Included in the pilot study is the student participation in online tutorials on deep learning and the implementation of the baseline architectures mentioned above.

 
\section{Conditions \& Schedule}
The experiments will be implemented in TensorFlow\cite{Abadi2015} and run on a GPU provided by CVAP.

\subsection{Schedule}
The literature study is already underway and will most likely continue somewhat into the project work.  We initially plan to allocate the 6 weeks between 14. of March to 24. of April to the design and implementation of the baseline architecture for both segmentation and pose estimation.  Following the baseline model we allocate the next 4 weeks until the 22. of May to the training and testing of a multi-task network for the two aforementioned tasks.  This includes setting up the datasets to be used for training simultaneous tasks.  Possibly, another 2 weeks until 5. of June will be assigned to more carefully examine the multi-task architecture as it includes recursive design and optimization with respect to architectural features mentioned in section \ref{sec:arc:optimization}.  If the research goes well we will look at more tasks but we only plan for two tasks.  Writing of the thesis needs to be done along side the work but the last four weeks, 30. of April to 26. of June, will have a heavier focus on writing and creating the presentation.

\bibliography{thesis}
\bibliographystyle{plain}

\end{document}
